<!DOCTYPE html>
<html>
<head>
    <!--
    * Author:         BeiYuu
    -->
    <meta charset="utf-8" />
    <title>【直播全文记录】基于Xapian的垂直搜索引擎的构建分析 | xiongjunnan.github.io</title>
    <meta name="author" content="Xiongjunnan" />
    <meta name="renderer" content="webkit">
    <meta name="description" content="Xiongjunnan's Blog" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0, minimum-scale=1.0">
    <link rel="stylesheet" href="/css/default.css" type="text/css" />
    <link rel="shortcut icon" href="/favicon.ico" type="image/x-icon" />
    <link rel="alternate" type="application/atom+xml" title="Recent Entries" href="/atom.xml" />
    <script src="/js/jquery-1.7.1.min.js" type="text/javascript"></script>
</head>
<body>

    

    <link rel="stylesheet" href="/js/prettify/prettify.css" />
<style type="text/css">
    body { background:#e8e8e8; }
    @media screen and (max-width: 750px){
        body { background:#fff; }
    }
    @media screen and (max-width: 1020px){
        body { background:#fff; }
    }
</style>

	<div id="content">
    <div class="entry markdown-body">
        <h1 class="entry-title"><a href="/xapian-analysis" title="【直播全文记录】基于Xapian的垂直搜索引擎的构建分析">【直播全文记录】基于Xapian的垂直搜索引擎的构建分析</a></h1>
        <p class="entry-date">2015-05-14</p>
        <p>此文根据【QCON高可用架构群】分享内容，由群内【编辑组】志愿整理，转发请注明出处。</p>

<blockquote><p>王晓伟, 2009年创办麦图科技专注于电商行业的垂直搜索, 受到多家天使,Pre-A投资机构的关注。有10+年互联网, 游戏, 内核安全从业经验. 历任软件工程师, 高级软件工程师, 技术经理,总监。目前主要从事手机游戏发行平台的构建, 推进公司Devops的培养和运维自动化的实施.</p></blockquote>

<h2>垂直搜索的应用场景</h2>

<p>下面是几张图片, 看下基本的业务场景<br/>
<img src="http://note.youdao.com/yws/api/group/9741968/noteresource/fd0f3250bc9cabfa5b6a3ee5bc1a320a/version/100?method=get-resource&amp;shareToken=A62213703ADA45B8978B5C9DAC8B2DB4&amp;entryId=60796715" alt="" />
<img src="http://note.youdao.com/yws/api/group/9741968/noteresource/dfb97ab57440422514af4c842c1a88b7/version/101?method=get-resource&amp;shareToken=A62213703ADA45B8978B5C9DAC8B2DB4&amp;entryId=60796715" alt="" /></p>

<h5>这是两个典型场景.</h5>

<ul>
<li>第一个场景基于拼音的搜索, 可以从开始处搜索, 可以从中间搜索.</li>
<li>第二个是常见的政府网站的搜索, 截图里说明存在的问题.</li>
</ul>


<h5>归纳一下业务场景有:</h5>

<ul>
<li>1、传统封闭系统的检索(ERP/CRM/OA, 知识管理系统, 站内搜索, 各种企业/电子政务系统的检索)</li>
<li>2、新型大众用户系统的检索(移动应用和桌面应用, 交互友好的WEB系统)</li>
<li>3、技术应用(拼音-汉字的检索, 自动补全, 对于推荐系统的支持)</li>
<li>4、解救数据库的like查询,根据数据库数据量级和文本长度不同, 性能可以提高数个量级</li>
</ul>


<h5>关于应用场景不做展开说明, 只举一两个例子:</h5>

<ul>
<li>很多政府信息公开网站的站内搜索使用数据库的like, 导致大量有用信息无法查询(参考图片), 需要用垂直搜索技术提高查询的质量</li>
<li>拼音查询, 文字起始处查询和文字中间查询(微信图片)</li>
<li>App本地搜索(微信图片)</li>
</ul>


<p>从应用场景上看, 目前在大数据, 用户产生数据的背景下, 搜索的需求是刚性的.</p>

<h2>技术选型</h2>

<h3>1. 检索引擎选型</h3>

<h4>彼时选型背景</h4>

<ul>
<li>Lucene以及基于Lucene的生态已经有了, 比如Solr.</li>
<li>Sphinx的生态也已经相对完整, 特别是基于mysql的全文检索(场景4)</li>
</ul>


<p>我们选择了xapian.</p>

<h4>几点原因:</h4>

<blockquote><p>1、相对完备的理论模型和技术实现,较早支持概率模型(BM2.5),彼时Lucene和sphinx不支持BM25(事实上都要晚上1,2年)</p>

<p>2.、鉴于1, 且Lucene早期版本更像一个实验性的项目, 只是实现了一些主要功能, 2次开发的工作量太大, 加之索引和检索的性能远低于C++实现的xapian.所以放弃了. 另外Solr定制灵活性较差, 比较适合整站页面抓取和全文索引处理, 不能满足对于电商产品的索引的需求(重点索引, 不需要全文)</p>

<p>3、 Sphinx与mysql结合过于紧密, 定制侵入性太强, 检索模型单一,更适合对于相关性排序和权重计算不那么高的全文检索, 所以同样放弃.</p></blockquote>

<h4>主要思路:</h4>

<blockquote><p>选型一定要了解业务和业务的价值, 垂直搜索的核心价值在于要对用户输入关键字的搜索意图要充分理解, 返回的结果的相关性, 权重排序要与用户高度匹配, 提高满意度, 所以对于检索模型和权重计算要求较高.</p></blockquote>

<p>比如彼时, Nokia N97很流行, iphone也很流行.当用户输入N97时, <strong>京东</strong>, <strong>亚马逊</strong>, <strong> 一号店</strong>绝大多数搜索出来的前10个几乎都为N97的配件, 而我们搜索的结果是N97手机.</p>

<p>这就是全文搜索和垂直搜索在本质上的差异.在这点上跟推荐系统有点像, 只不过推荐系统是根据用户的历史足迹和行为推定出来, 而垂直搜索是通过关键字.某些情况下, 两者可以相互融合.</p>

<h3>2. 存储选型</h3>

<blockquote><p>关于存储选型的一些看法. 这部分主要从笔者所接触的系统着眼, 从今天来看也许不一定正确, 主要分享下思路.</p></blockquote>

<p>我们选择了Cansandra+MongoDB,而不是HDFS/HBase</p>

<h4>几点原因:</h4>

<blockquote><p>1、不选择HDFS的原因很简单, HDFS处理小文件是个坑, 空间浪费大, 文件一多, 检索性能慢. 彼时HDFS没有现在这么稳定, NameNode会因为莫名的原因阻塞. HDFS文件管理跟普通的文件系统原理相同, 同命名空间节点有限, 需要多级目录管理, 最终检索太费劲</p>

<p>2、 HBase基于HDFS, 性能一般, 检索困难, Scheme定义没有MongoDB灵活. 不过现在好多了. 同样都有单点故障, 彼时创业公司运维能力和资源没有那么多, 感觉维护不来.</p>

<p>3、Cassandra 和MongoDB搭档基本解决我们问题: 包括扩容方便, 检索便利, scheme自由度高.首先Cassandra是去中心化的,只要不是几个机架一起坏,一般不会有事; 基于一致性hash的数据分布, 扩容比较无忧, 会自协调; 根据配置可以做到多份 replica, 有容灾能力.</p>

<p>4、 MongoDB我们最初用的是1.x版本, 功能雏形已经全了, 检索方便, 支持js的mapreduce. 我们是基于Ruby和C++开发, 而MongoDB最早支持Ruby.</p></blockquote>

<p>创业公司选型最大的问题是时间问题. 我们不能停下来选型而不做业务. 这是个比较大矛盾. 上面提到的几点经验希望对大家有所借鉴.</p>

<h2>垂直搜索引擎架构的介绍</h2>

<blockquote><p>分享下5000W数据以内的垂直搜索引擎的架构模型.模型中也涉及到了流式计算, 当然彼时流式计算并没有如此完整的模型和开源项目的支持.我们可谓是蛮干了一把.此处可以参考王新春老师的<a href="http://xiongjunnan.github.io/realtime-compute/">实时计算在点评</a>中内容做个比较(当然结论是, 我们还是很山寨的).</p></blockquote>

<p>整体架构包含以下部分:</p>

<h3>1. 种子发生器</h3>

<p> 用于入口页面的发布, 可以根据需求定义粒度, 比如整个 http://www.jd.com 是一个入口, 夺宝岛 : http://auction.jd.com/index.action 也是一个入口.后面会介绍业务场景.</p>

<p>以 http://www.jd.com 为入口, 是实时性要求不高的数据. <br/>
以 http://auction.jd.com/index.action 为入口是实时性要求很高的业务</p>

<h3>2.  抓取系统（Cralwer）</h3>

<p>单进程单线程异步多工方式抓取, 分布部署, 容错性,健壮性为主. 通用的模块,与具体站点和业务无关, 只负责抓取, 抓取的URL最初由种子发生器发出, 后面有Parser页面解析系统分析URL再填充. Crawler是一个不会停止的系统.Crawler的数据key和meta-data存储于MongoDB, 页面的 RAW 数据存储于 Canssandra. crawler. 除了容错性,健壮性之外, 性能其实非常重要.</p>

<h3>3.  页面解析器（Parser）</h3>

<p>业务相关, 从 MongoDB 和 Cassandra 获取数据负责对页面进行符合业务需求的分析, 根据关键字, URL特征和预置的规则将页面URL和部分数据提取出来, 另外实现查重的功能(几亿数据查重, 采用 bloomfilter + Redis 实现 )</p>

<p>bloomfilter的及时引入确实很救命. 数据检索更新和查重节省了很多时间. 不过与redis适配当时有点问题, 另外虽然redis很快, 但是有条件还可以再优化.</p>

<h3>4.  数据分析器（Analyser）,</h3>

<p>语料分析, 真正的业务核心.将HTML的页面数据提取成结构化的数据, 存储到MongoDB.整个架构最精彩的部分也在这里. 如何能做到处理几十家不同网站数据提取和规整, 并能跟上源站更新的节奏(当时某东, 几乎天天更新), 又便于多人并行开发和更新, 低耦合, 互相隔离, 持续部署是一个有趣的问题.</p>

<h3>5. 索引器（Indexing）</h3>

<p>完成从 MongoDB 取数据, 分词/语法分析/部分语义分析, 计算预置权重, 完成索引.该模块完成一堆数据到信息的提炼, 直接影响了用户查询结果的质量和满意度, 比如判断语义, 相关性排序等.</p>

<p>索引工作从代码层面不难, 条用几个函数把数据添加即可, 但是其实功夫都花在前面了. 索引和检索是垂直搜索引擎的大脑, 是思考的部分.性能要好, 结果要准.</p>

<h3>6. 图片到文字的提取识别（Ocr）</h3>

<p> 最初测试过 Tesseract OCR ( 由HP开源, 后来由 Google 赞助的一个项目), 但是后来发现不实用, 样本学习过程繁琐, 更新不方面, 关键识别太慢. 后来我们手动写了一套专门只针对数字的识别的服务.Ocr处理会在索引之前完成.</p>

<p>这一部分很多时候不是必须的, 当时主要针对某东和后来本鹅厂收购的某讯.现在某东已经不是图片了.</p>

<p>下面来一张图, 大概表示一下这之间的逻辑, 分层关系图中表现的不是特别准确.核心中间件是RabbitMQ</p>

<p><img src="http://note.youdao.com/yws/api/group/9741968/noteresource/fde09a7358d71885129301ce89188db6/version/102?method=get-resource&amp;shareToken=A62213703ADA45B8978B5C9DAC8B2DB4&amp;entryId=60796715" alt="" /></p>

<p>后来有所改进, 我们把CWS也单独抽取出来. 自己写了一个简单的MQ Agent, 基于Redis实现的, 性能比RabbitMQ要好很多. 建议有条件可以使劲的Hack.</p>

<h2>垂直搜索技术和业务细节</h2>

<h3>1. 如何提高垂直检索质量和语义识别</h3>

<p>其实语义识别本身是很难的,但是一定的关键词集合里是可以做到的优化的.
比如前面提到的, 搜索”N97 手机”搜索一堆手机配件的问题, 因为手机和手机配件含有相同的关键字. 传统的相关度, 权重的模型是基于语料库, TF/IDF做的.但是商品的名称文字是很短的, 基本上都只会出现一次, 名称相似度也没有可以参考的, 那怎么办呢?</p>

<p>这种情况我们就需要预置权重. 我们编写了一套学习的工具, 通过分类, 品类, 建立了词干, 词根的树形结构, 同时设定没层的权重, 那么用户在搜索的时候, 匹配从根部开始, 那么就很避免了搜出树枝部分.</p>

<p>这是个非常繁琐细致的工作, 要分析整个商品库, 人工很难. 需要有一套启发式的词根更新的方法和工具.</p>

<h3>2. 如何应对不同众多异构数据模型</h3>

<p>先发一张图, 图中列出了对于不同站点检索的模板文件的管理结构</p>

<p> <img src="http://note.youdao.com/yws/api/group/9741968/noteresource/cc052b747b70507259c1bf7bd269b54e/version/103?method=get-resource&amp;shareToken=A62213703ADA45B8978B5C9DAC8B2DB4&amp;entryId=60796715" alt="" /></p>

<p>这是其下层目录的结构.<br/>
<img src="http://note.youdao.com/yws/api/group/9741968/noteresource/63e85430c2f6f05ee9368f740455486a/version/104?method=get-resource&amp;shareToken=A62213703ADA45B8978B5C9DAC8B2DB4&amp;entryId=60796715" alt="" /></p>

<p>前面提到我们是做电商的垂直搜索的, 需要从源站获取商品信息: 商品名称, 价格, 图片, 规则参数, 详细介绍, 评论.</p>

<p>显然每个源站都不一样, 要适配40几家网站需要一种独立, 易更新的, fast-fail的, 错误自容的架构.这样能保证开发可以并行, 源站更新可以快速适配, 出现错误不影响其他模块.</p>

<p>一开始的做法是在代码里做各种if/else, 但是这样导致并行开发代码合并问题很大; 后来用插件式编程, 这样动态加载模块看上不错, 但是会污染代码运行环境, 运行久了容易出一些莫名其妙的bug.</p>

<p>后来我们采取了基于模板语言的方法, 把业务逻辑封装到一个模板文件, 此文件结构本身是HTML, 通过\&lt;script>标签把我们业务代码放到HTML里. 这样好处是, 业务代码跟要解析的HTML在一起, 方便代码提取数据的逻辑调试, 同时业务代码运行环境局限在模板本身, 即使出了问题也不会污染到其他代码.</p>

<p>为此的代价是开发一套工具用于模板编写调试.</p>

<h3>3 .关于算法选择</h3>

<p>算法一定不是万能的,现在计算权重,相关性的算法很多, 我们尝试过基本的布尔, BM25, SVM, Cosine similarity等等. 其实这些算法直接应用到现实的业务都不灵. 那为啥会有这么高大上的算法存在呢?</p>

<p>我们的经验是: 想要发挥算法奇效, 要靠数据索引前的预处理, 所以踏踏实实做数据处理,分析业务,然后理解数据与算法的结合点最终才能做到相得益彰, 检索出符合用户心理的结果.</p>

<h2>Q&amp;A</h2>

<h5>Q1: 请问使用的中文分词器是什么，自研的还是其它；拼音搜索是如何实现的，是在新建索引时将转换为拼音存起来吗</h5>

<p>1、中文分词器: 基于scws. 国人开源之作. 自行开发了ruby和python的binding.<br/>
2、拼音搜索是如何实现的, 如你所言 要事先索引.<br/>
3、补充一点, 类似Google的搜索纠错(编辑距离算法), 智能补全等都可以通过预置的方法实现</p>

<h5>Q2: 数据分析器，分析html代码的时候，如何解决ajax的问题？</h5>

<p>解决ajax的问题: 我们遇到某宝是这样的, 一开始想开发一套基于webkit的工具处理, 后来发现性能太差, 而且某宝ajax请求基本稳定, 所以在模板里直接发起HTTP搞定. 或者也可以在parser阶段取出相关url进行处理. 这里我们没找到通用的解决方案.</p>

<h5>Q3: 重新让你选择一次，目前情况下你会做哪些选型上的改进？</h5>

<p>1, 业务量不增加的情况下, 索引和存储层面我可能不太会做更多改变.
2, 技术架构上, 对于crawler及其他几个模块的实现要改, 之前是自行开发的并行结构, 健壮性还行, 但是维护难度高, 适合采用现在流行的并行计算的架构.</p>

<h5>Q4: 基于Redis实现了一个MQ Agent, 是基于Redis的队列实现的吗？为什么没有直接用Redis的Pub/Sub？ 还有这个有做集群实现吗？</h5>

<p>1, 自己开发是将一些业务放进了Agent. 便于集中优化. <br/>
2, 未做集群, 做了主备.</p>

<h5>Q5: 拼音库是怎么实现的？有支持模糊音匹配吗？</h5>

<p>1、拼音库有现成的,如果觉得不可靠可以通过Character Map提供的数据自己做一份. <br/>
2、模糊音匹配我的理解应该就是纠错, 根据编辑距离, 前提是你有把握识别出这是用户输入错误.看下图:
<img src="http://note.youdao.com/yws/api/group/9741968/noteresource/52254d53c2cbb5ffbc541ff37455aaba/version/106?method=get-resource&amp;shareToken=A62213703ADA45B8978B5C9DAC8B2DB4&amp;entryId=60796715" alt="" /></p>

<h5>Q6: 用户的意图你们是怎样预期及理解的？</h5>

<p>我们是靠语料的数量, 我们直接能假定用户不是调戏我们的. 完后再通过一些算法, 比如纠错, 拼音, 引导提示和补全等猜测. 还有最重要的是:
1、 数据权重计算要理解源站数据组织的用意, 比如首页的数据显然很重要. <br/>
2、预置权重, 比如现在搜索iphone, 我们应该排第一位的是iphone6, 而不是iphone5或者4.<br/>
3、昨天王新春老师提到的根据用户行为, 这个只会体现给当前用户.其他用户不能简单的应用</p>

<h5>Q7: 请再稍微具体展开下权重计算 和检索模型这块儿？N97手机的例子，怎样做到排除干扰词影响的？如N97手机和N97手机壳.</h5>

<p>原理如下:
1、我们算法如下: 手机是一个分类, 手机壳是一个分类, 两个在一起权重下降( 算法不在这里体现).<br/>
2、如果只是输入N97, 我们数据是可以启发认知为 N97 手机<br/>
3、手机和手机壳有自身的权重, 手机高于手机壳 <br/>
4、手机壳可以排除手机, 但是手机排除不了手机壳</p>

<h5>Q8: mongoDB的库级锁对吞吐量的影响是怎样优化或规避的？</h5>

<p>1、这个我无法从MongoDB本身回答, 我的经验是, mongodb driver for ruby(理论上其他的也是)是异步写的, 所以写不会阻塞. <br/>
2、读是泛读, 所以不会引起读到不存在的数据的情况</p>

<h5>Q9: 基于模版的业务逻辑放到html的script里面，业务开发人员在这个框架如何进行代码调试</h5>

<p>1、最重要的我们API是详尽和傻瓜的, 用法明确, 完全满足数据操作的要求, 杜绝了开发人员用错API或者没有API可以用.<br/>
2、我们开发了console用于测试. 这个测试主要测试数据是否正确, 并非要调试.当然也支持调试, 这个是ruby提供的debugger特性.</p>

<h5>Q10: 爬虫获取的Url反垃圾怎么做的？比如Url陷阱，无效参数之类的？</h5>

<p>1、我的回答可能会有点遗憾, 垂直搜索对于URL的粒度的把控是很细的.所以我们从业务上就可以杜绝. <br/>
2、我们尽可能让系统多做事, 基于fast-fail, 我们工程师只等待系统fail的通知, 所以如果出错了我们会有人跟进. <br/>
3、如果不是infinite-loop我们也不是特别在乎.</p>

<h5>Q11: 单进程单线程设计师基于什么考虑的？</h5>

<p>1、我纠正我的说法, 我想说的是一个进程只有一个线程, 部署其实是多进程的.<br/>
2、我是windows程序员出身, 写了6年多的windows程序, 写过很多多线程的程序, 我发现一旦陷入到多线程, 程序员就开始不关心业务, 开始跟多线程斗争(多数人对于操作系统的一些原理没学好). 所以我7年前转到linux之后, 程序全部采用单线程+异步的模型.  <br/>
3、单线程模型简单, 类库好写, 数据读写易管理, 不易出错, 出错后好排查.</p>

<h5>Q12: 从html中提取结构化数据是你们是用正则还是基于css or dom?</h5>

<p>基于dom. css/xpath 正则建议不要用于复杂数据,变动性强的数据和大规模数据, 不易调试和维护.</p>

<h5>Q13: 排序会用到用户日志的学习及训练吗？</h5>

<p> 当时的设计是通过朋友收藏, 社交上connection + 搜索权重训练. 从日志学习没有, 主要是没有想到好的防止作弊的方法.</p>

<h5>Q14: 最近搜索遇到一个需要存储时间纬度的需求，而且是几十天，能通过建索引解决吗？</h5>

<p>我不是很明白问题的需求, 我觉得应该可以.</p>

<h5>Q15: 如果现在你选，你还是用RabbitMQ吗，有没有考虑kaffka？ 自己实现基于MQ Agent，是否类似于github开源的resque？Mongodb写入不可靠的问题有碰到吗，有用shard吗？</h5>

<p>1, 参照尽量Hack的理念,可能会换. <br/>
2, 自己实现目的只有两个, 保证数据处理序列的情况下, 可以批量处理. 跟resque理念不同. 细节有点遗忘, 主要是把业务放到MQ Agent上了. 订阅者可以跟agent在业务层面上做约定.   mongodb我们是全架构的, Shard+ replication</p>

    </div>



    <div class="sidenav">
        <h2>官方出版</h2>
        <ul class="artical-list">
        
            <li><a href="/xapian-analysis">【直播全文记录】基于Xapian的垂直搜索引擎的构建分析</a></li>
        
            <li><a href="/realtime-compute">【直播全文记录】实时计算在点评</a></li>
        
        <h2>成员精华</h2>
        <ul class="artical-list">
        
        </ul>

        <h2>常用资源</h2>
        <ul class="artical-list">
        
            <li><a href="/favorite-blog-list">经常关注的技术博客</a></li>
        
            <li><a href="/favorite-article-list">收藏比较经典的技术文章</a></li>
        
        </ul>

        
        </ul>
    </div>
</div>

<script src="/js/post.js" type="text/javascript"></script>

	
    <div class="home-menu">
        <div class="home-icon-con">
            <a class="home-menu-icon" href="/">QCON高可用架构群官方博客</a>
            <a class="home-follow" href="#" title="Contact Me">+</a>
        </div>
    </div>

    <script type="text/javascript">
        $(function(){
            $('.home-follow').click(function(e){
                e.preventDefault();

                if($('.home-contact').is(':visible')){
                    $('.home-contact').slideUp(100);
                }else{
                    $('.home-contact').slideDown(100);
                }
            });
        })
    </script>
</body>
</html>
